question,answer
What are the main differences between cross-entropy loss and KL divergence when training deep learning models?,"Cross-entropy measures the distance between the true distribution p and predicted distribution q and is defined as: H(p, q) = – Σ p(x) log q(x). KL divergence measures how much information is lost when approximating p with q: KL(p || q) = Σ p(x) log(p(x)/q(x)). Cross-entropy = entropy + KL divergence. KL is asymmetric and used for distribution matching; cross-entropy is directly optimized in classification."
"In gradient boosting, why does using a learning rate (shrinkage) reduce overfitting?","Shrinkage scales each weak learner’s contribution (e.g., f = f + η * h) which forces the model to learn slowly. This reduces overfitting because each tree corrects residuals in smaller steps, increasing generalization and providing regularization similar to L2 shrinkage."
Explain the difference between L1 and L2 regularization in terms of optimization geometry.,"L1 regularization uses the L1 norm, producing a diamond-shaped constraint region, which increases the chance of the optimal solution landing on an axis → sparse weights. L2 uses a circular constraint, discouraging large weights but rarely driving them to zero → smooth shrinkage."
Why does PCA fail when the data is not centered?,"PCA assumes the covariance matrix is computed around zero mean. If the data is not centered, the first principal component may capture the mean offset rather than variance direction, producing incorrect eigenvectors and distorted projections."
How does dropout approximate an ensemble of neural networks?,"During training, dropout randomly deactivates neurons, creating different “thinned” network architectures. This behaves like averaging predictions from many subnetworks, reducing co-adaptation and variance (similar to bagging but within a single model)."
Why is the Adam optimizer sometimes inferior to plain SGD for large-scale training?,"Adam uses adaptive per-parameter learning rates that can cause the optimizer to converge quickly into sharp, high-curvature minima that generalize poorly, whereas SGD with momentum injects uniform noise that helps escape sharp minima and find flatter, more stable basins, leading to better generalization in large-scale training; additionally, Adam’s aggressive adaptive updates can lead to overfitting on smaller datasets and introduce bias when gradients are sparse or inconsistent."
"When performing A/B testing, what is the impact of underpowered experiments?","Underpowered A/B tests produce unreliable estimates because small sample sizes dramatically increase the probability of Type II errors, inflate observed effect sizes when significant results do occur, reduce reproducibility, and create misleading business decisions by making the experiment extremely sensitive to random noise rather than actual treatment effects."
Explain how SHAP values approximate Shapley values mathematically.,"SHAP approximates Shapley values by decomposing model output into additive feature contributions using a weighted linear regression framework where weights mimic the Shapley kernel, and for tree-based models TreeSHAP computes exact Shapley values in polynomial time by exploiting tree structure via path-dependent expectations rather than evaluating all 2ⁿ subsets, making the theoretically exponential computation tractable."
Why does multicollinearity not affect prediction accuracy but affects interpretability in linear regression?,"Multicollinearity causes coefficient estimates to become highly unstable and sensitive to minor data perturbations because correlated predictors make the design matrix nearly singular, but prediction accuracy remains high since the combined information across correlated variables still captures the same signal; interpretability suffers because individual coefficients cannot be meaningfully attributed to specific features when their effects are inseparable."
"In time series forecasting, why do ARIMA models struggle with long-range dependencies?","ARIMA relies on linear auto-regressive and moving-average components that only capture short-term dependencies encoded by fixed-order lag terms, making it incapable of modeling hierarchical, nonlinear, or long-range temporal interactions, whereas modern architectures like LSTMs, TCNs, and Transformers incorporate dynamic memory or self-attention that allows them to represent much longer temporal horizons effectively."
Why does batch normalization speed up convergence?,"Batch normalization stabilizes the distribution of intermediate activations by normalizing them across each mini-batch, reducing internal covariate shift, improving gradient flow, enabling the use of larger learning rates, smoothing the optimization landscape, and reducing sensitivity to initialization, all of which collectively accelerate convergence and improve model robustness during training."
Why is cosine similarity preferred over Euclidean distance for text embeddings?,"Cosine similarity measures the angle between high-dimensional vectors and is therefore invariant to magnitude, making it ideal for text embeddings where semantic meaning is encoded primarily in direction rather than length, whereas Euclidean distance is scale-sensitive and often meaningless in sparse, high-dimensional embedding spaces where vector norms vary widely without reflecting semantic differences."
Explain the bias–variance tradeoff using ensemble methods (bagging vs boosting).,"Bagging reduces variance by training multiple independent models on bootstrapped samples and averaging their predictions to cancel out instability, whereas boosting reduces bias by iteratively training new models that focus on errors made by previous ones, effectively building a strong learner from many weak learners, but boosting can increase variance and overfitting risk if the weak models become too expressive."
Why does class imbalance cause poor recall for minority classes?,"Class imbalance biases the learning algorithm toward predicting the majority class because the loss function, gradient magnitudes, and decision thresholds become dominated by frequent examples, causing the classifier to underfit minority examples, shrink minority decision regions, and produce poor recall by failing to recognize rare but important patterns."
How does t-SNE preserve local structure but distort global structure?,"t-SNE converts pairwise distances into conditional probabilities that emphasize nearest-neighbor relationships and minimizes KL divergence between high-dimensional and low-dimensional distributions, strongly preserving local neighborhoods while intentionally separating clusters and compressing or expanding global distances, leading to high-quality local structure at the cost of global geometry distortion."
Why does regularization help in logistic regression but not in Naive Bayes?,"Logistic regression directly optimizes parameters via maximum likelihood, so L1/L2 regularization penalizes large weights and mitigates overfitting, whereas Naive Bayes computes closed-form probabilities grounded in strong independence assumptions that already restrict model flexibility, meaning weight regularization has limited impact on generalization because the model structure, not the parameters, is the primary constraint."
How do attention weights in a Transformer enable long-range dependency modeling?,"Transformers compute attention scores between all pairs of tokens in a sequence, producing weighted combinations that allow each position to aggregate information from arbitrarily distant tokens in a single layer, enabling efficient long-range dependency modeling without recurrence and resulting in superior context propagation compared to RNNs or CNNs."
Why are convolutional networks translation-equivariant?,"Convolutional networks apply shared kernels across spatial locations so that shifting the input causes a proportional shift in the output feature map, making the network inherently translation-equivariant and allowing consistent feature detection independent of where patterns appear in the input image."
What is the purpose of negative sampling in Word2Vec?,"Negative sampling simplifies the training of the Word2Vec skip-gram model by replacing the expensive full softmax with a binary classification objective where the model differentiates true word-context pairs from a small set of randomly sampled negative examples, drastically reducing computational cost while still producing high-quality distributed representations."
Why do tree-based models fail to extrapolate outside the training range?,"Tree-based models partition the feature space into fixed regions based on observed data and assign constant or simple predictions within each leaf, so when inputs fall outside the training range the model simply outputs the value from the nearest leaf instead of extending the learned pattern, leading to flat extrapolation and poor generalization beyond seen values."
